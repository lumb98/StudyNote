# 操作系统





## 内存管理

### 内存碎片

由于内存分段的原因会导致系统内存存在一些内存碎片，因为这些内存碎片，当我们新开启一个进程时，会发现总的剩余内存是够用的，但是却因为内存不足无法打开新的进程，这是因为一块大的内存呗分为了多个小的内存空间，这种情况就叫做内存碎片。

### 内存交换 swap

内存交换技术可以改善内存碎片的问题，我们把造成内存碎片的那一段内存暂时存到硬盘中，再从硬盘取出放在紧靠其他进程内存段的位置，这样就解决了内存碎片的问题，而用到的这部分硬盘就是Linux系统中的swap空间，而硬盘读写和内存的读写速度相差甚远，这就导致了进行这个内存交换的过程会造成卡顿，尤其再交换占用内存大的进程时，为解决这一问题就引入了**内存分页**。

### 内存分页

分页就是将内存空间切分成一段段**固定尺寸**的大小，每一个固定尺寸的空间就被称为**页**。在Linux下每一页的大小为`4KB`,这样做有一下几点好处：

1. 可以减少内存碎片的出现
2. 可以动态的进行内存交换，只将应用长时间未用的内存所在的那些页做内存交换，不需要将大部分的内存做交换，免得大动干戈。
3. 在程序开始运行时只把需要用到的指令和数据加载到物理内存中，可以随用随取。

### MMU(内存管理单元)

MMU主要工作就是将虚拟内存的虚拟地址通过页表映射到物理地址中。如果进程访问的虚拟地址在页表中查不到，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。

### 分页的映射方式

在分页机制下虚拟地址分为两部分，分别是**页号和页内偏移量**，其中页号会到页表中寻找对应的物理页号，而因为内存被规则的分为一定大小的页，所以页内偏移量则可以直接对应到物理地址。

### 多级页表

简单分页的方式相对于内存分段来说固然有很多优势，但它还是不够好。

最重要的原因之一，就是页表本身也需要占用内存，在32位系统中(最大4G内存），页大小位4KB(2^12)的情况下，大概需要2^20个页，每个页表项需要占用4个字节的大小来储存，那么4GB就需要用到4MB的内存，而且每个进程都有一个页表，假设有100个进程，就需要用到400MB内存，这是相当浪费的。

多级页表的出现就是为了解决这一问题。我们可以把页表分成二级，将一级页表分为1024个二级页表，再让二级页表对应到物理内存，这样做，每个二级页表只需要有1024个页就可以了，但是假设一个程序要使用全部的4G内存，那么它就要占用4KB+4MB的内存用作页表的储存了，但实际上并不会用到这么多的内存（当然是在32位机时代），即使有也不会是所以的内存都是活跃的，我们可以将不需要的内存做内存交换。现在假设一个进程只用了20%的一级页表，那么它占用的内存就是：`4KB+20%*4MB=0.804MB`相对于单机页表的4MB少了很多，你可能会有疑问，为什么在单级的情况下我用20%的内存为什么不是0.8MB呢？这是因为如果虚拟地址在页表中找不到对应的页表项，那计算机系统就无法正常工作了，**页表一定要覆盖全部的虚拟地址才可以**。

在64位系统中采用的方式是**四级目录**，它们分别是：

* 全局页目录项 PGD（Page Global Directory）；
* 上层页目录项 PUD（Page Upper Directory）；
* 中间页目录项 PMD（Page Middle Directory）；
* 页表项 PTE（Page Table Entry）；

在加上页内偏移量（OFFSET)就可以精准映射到物理内存了。

### TLB（Translation Lookaside Buffer）

TLB通常称为页表缓存、专职旁路缓存、快表等。

因为程序的运行是由局部性的，所以我们可以将常用的页存在TLB中，TLB是CPU中的一个专用于存放程序最常访问的页表项的Cache，CPU会先访问TLB如果在TLB中没有才会去页表中找。

### 段页式内存管理

可以将前面讲的分段式内存管理和分页式内存管理结合起来，组成段页式内存管理。

先将内存分成几个段，比如代码段，数据段和栈段，然后再将段内的内存分为数个页。每个段对应一个自己的页表，再由页表对应到物理内存。

如果这样分配就可以将地址结构分为**段号、段内页号和页内位移**三部分。



### Linux的内存管理

以页式内存管理为主，但由于Intel的历史问题不得不涉及段机制。

Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是一样的。这意味着，Linux 系统中的代码，包括操作系统本身的代码和应用程序代码，所面对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被用于访问控制和内存保护。



### malloc()如何分配内存

会通过`brk()`和`mmap()`两种方式，二者的主要区别是`brk()`是将堆顶指针向高地址移动，从而获得一块空闲的内存，而`mmap()`则是通过在文件映射区分配一块内存来创建内存。

什么时候用哪一个的主要通过`malloc()`源码中定义的一个阈值来确定：

- 如果用户分配的内存小于 128 KB，则通过 `brk()` 申请内存；
- 如果用户分配的内存大于 128 KB，则通过 `mmap()` 申请内存；

并且`malloc()`分配的内存如果**没有被访问，是不会映射到物理内存中的。**只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发缺页中断，然后操作系统会建立虚拟内存和物理内存之间的映射关系。

并且这两种分配方式在`free()`的时候也会有不同的结果。

- malloc 通过 **`brk()`** 方式申请的内存，`free `释放内存的时候，并不会把内存归还给操作系统，**而是缓存在 malloc 的内存池中，**待下次使用,下次再申请内存时就不用进行**内核态和用户态的切换**，也**不会出现缺页**的情况。；
- malloc 通过 **`mmap()`** 方式申请的内存，`free `释放内存的时候，**会把内存归还给操作系统，内存得到真正的释放**。

#### `malloc(1)`会分配多大的内存？

`malloc()`并不会完全根据我们输入的字节大小来分配内存，它会根据情况，预分配更大的空间作为内存池。之前做了一个实验当我们`malloc(1)`时实际分配的内存有132K。

###  free() 函数只传入一个内存地址，为什么能知道要释放多大的内存？

还记得，我前面提到， malloc 返回给用户态的内存起始地址比进程的堆空间起始地址多了 16 字节吗？

这个多出来的 16 字节就是保存了该内存块的描述信息，比如有该内存块的大小。

这样当执行 free() 函数时，free 会对传入进来的内存地址向左偏移 16 字节，然后从这个 16 字节的分析出当前的内存块的大小，自然就知道要释放多大的内存了。



### 内存的回收机制OOM

当系统的内存不足时就会触发内存回收机制，把一些使用频率低的内存进行回收而被回收的这些内存主要可以分为两类，分别是文件页和匿名页。

- **文件页**（File-backed Page）：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。大部分文件页，都可以直接释放内存，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放。所以，**回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存**。
- **匿名页**（Anonymous Page）：应用程序通过 mmap 动态分配的堆内存叫作匿名页，这部分内存很可能还要再次被访问，所以不能直接释放内存，它们**回收的方式是通过 Linux 的 Swap 机制**，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。

这里要注意这两个的区别，对于文件页的回收，如果回收的是干净页几乎可以无损回收，因为它可以直接释放内存，而脏页的回收则需要进行磁盘I/O，同时匿名页的回收也是需要进行磁盘I/O，但这两种回收方式都是基于LRU算法的。

常规的回收方式主要有两种，分别是**后台内存回收(kswapd)**和**直接内存回收(direct reclaim)**，当这两种回收机制都不能满足内存申请的需求时，则会使用**OMM(Out Of Memory)机制**。

- **后台内存回收**（kswapd）：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程**异步**的，不会阻塞进程的执行。
- **直接内存回收**（direct reclaim）：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是**同步**的，会阻塞进程的执行。

OOM Killer 机制会根据算法选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，如果物理内存依然不足，OOM Killer 会继续杀死占用物理内存较高的进程，直到释放足够的内存位置。

具体的流程会根据系统当前剩余能存的大小和系统设定的几个参数来决定，其中`/proc/sys/vm/min_free_kbytes`定义了参数`pages_min`又可以根据这个参数计算出`pages_low`和`pages_high`当内存页`pages_free`处于`pages_low`和`pages_min`之间时，就会采用`kswapd`方式进行内存的回收，一旦内存页小于`pages_min`时就会启用直接内存回收。

此外还可以通过`/proc/sys/vm/swappiness`参数来调整文件页和匿名页的回收倾向，当等于0时会尽可能回收文件页。

如果后台内存回收和直接内存回收都无法满足系统的需求，那么就会启用OMM机制，OMM机制会对进程进行评分，评分的表尊主要有以下两点：

- 第一，进程已经使用的物理内存页面数。
- 第二，每个进程的 OOM 校准值 `oom_score_adj`。它是可以通过 `/proc/[pid]/oom_score_adj` 来配置的。我们可以在设置 -1000 到 1000 之间的任意一个数值，调整进程被 OOM Kill 的几率。

一般情况下`omm_score_adj`的默认值是0，只会根据进程已使用的物理内存页面数进行评分，这个值的范围的-1000~1000，如果我们不想让某个进程被OOM杀死，可以设置这个值位-1000，但只有极必要的进程才有必要这样设置。`omm_score_adj`还要乘几个参数，最后和已经使用的物理内存页面数相加，最后得分高的会被优先杀死。



## 进程管理

### 进程间的通信方式

在Linux中进程间的通信方式主要分为**管道、消息队列、共享内存、信号量、信号和Socket**六种。

### 管道

* 管道是一种单向通信方式，要想达到双向通信的目的需要创建两个管道。

平时我们在shell中使用的命令

```shell
ps auxf | grep mysql
```

中的`|`所代表的就算一个管道，它的作用是将前一个命令的输出作为后一个命令的输入，这里面的`|`是一个**匿名管道**，因为它并没有对应的文件，甚至没有名字，它仅存在于内存中，若想创建并命名一个管道，可以使用下面的命令：

```shell
mkfifo myPipe
```

像这这样的**命名管道**也被叫做**FIFO**。

我们可以用以下命令堆管道进行读写：

```shell
echo "hello" > myPipe    #将数据写入管道
#这是命令会在这里卡住，因为我们没有读取整个管道。我们得读了整个管道echo才能正常退出。
cat < myPipe             #读取管道里的数据
hello
```

* 可见管道通信虽然方便但是其效率偏低。

匿名管道的创建可以通过以下命令：

```shell
int pipe(int fd[2])
```

它会返回两个描述符，其中`fd[0]`是读取端的描述符，`fd[1]`是写入端的描述符。Linux操作系统在fork时会保留文件描述符，这样匿名管道就可以达到通信的目的了。



### 消息队列

消息队列可以解决管道效率低的问题。

### 信号量

信号量实际上就是一个整型计数器，只要用于实现进程间的互斥和同步，一般不用于数据的传输。

信号量有两个原子操作：

- 一个是 **P 操作**，这个操作会把信号量减去 1，相减后如果信号量 < 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 >= 0，则表明还有资源可使用，进程可正常继续执行。
- 另一个是 **V 操作**，这个操作会把信号量加上 1，相加后如果信号量 <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 > 0，则表明当前没有阻塞中的进程；

P 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的。
